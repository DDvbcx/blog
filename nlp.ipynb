{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在进行文本相似度分析的步骤：\n",
    " 1. 文本预处理 ： 对于拿到的文本资料进行分词，去除停用词，词性标注，归一化处理等。\n",
    " 2. 文本特征提取 ： \n",
    "  * 词袋模型\n",
    "  * TF-IDF\n",
    "  * 词嵌入\n",
    " 3. 计算相似度：\n",
    "  * 计算余弦相似度\n",
    "  * 欧氏距离\n",
    "  * Jaccard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单词的表示\n",
    "要让计算机理解单词的含义，有以下方法：\n",
    " * 基于计数的方法\n",
    " * 基于推理的方法(也称基于分布式表示)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 使用 TF-IDF 和余弦相似度计算文本之间的相似度\n",
    "TF-IDF 是一种常用的文本特征提取方法，用于衡量一个词在文档集合中的重要性。TF-IDF 结合了词频（Term Frequency, TF）和逆文档频率（Inverse Document Frequency, IDF）两个概念。   \n",
    "词频（TF）：表示一个词在文档中出现的频率。    \n",
    "逆文档频率（IDF）：表示一个词在所有文档中出现的稀有程度。    \n",
    "公式为: ```TF-IDF(t, d)=TF(t, d) * IDF(t)```\n",
    "其中： ```TF(t, d) = 词 t 在文档 d 中出现的次数/文档 d 中总词数```   \n",
    "    ```IDF(t) = log(语料库中的文档总数/包含词 t 的文档总数)```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity:[[0.17077611]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "text1 = ['I like to play football.']\n",
    "text2 = ['I love playing football.']\n",
    "\n",
    "text = text1 + text2\n",
    "# 初始化 TF-IDF 向量化器\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# 将文本数据转换为 TF-IDF 特征向量\n",
    "tf_vecs = vectorizer.fit_transform(text)\n",
    "\n",
    "tf_vec1 = tf_vecs[0:1]\n",
    "tf_vec2 = tf_vecs[1:2]\n",
    "\n",
    "# 计算余弦相似度矩阵\n",
    "cosine_sim = cosine_similarity(tf_vec1, tf_vec2)\n",
    "print(f\"Similarity:{cosine_sim}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf_vec1: [[0.37997836 0.53404633 0.         0.53404633 0.         0.53404633]]\n",
      "tf_vec2: [[0.44943642 0.         0.6316672  0.         0.6316672  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "'''TF-IDF 使用的是基于计数的方法'''\n",
    "print(f\"tf_vec1: {tf_vec1.toarray()}\")\n",
    "print(f\"tf_vec2: {tf_vec2.toarray()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于词嵌入的计算文本相似度\n",
    "词嵌入主要是将文本中的单词表示为一个向量，如果文本```text```有10个单词，我们将每个单词对应的向量维度定义为300维，那么这句话可以表示形状为为(10, 300)的此矩阵。   \n",
    "词嵌入通过训练神经网络模型在高维空间中为每个单词生成一个向量，这些向量可以捕捉单词的语义和上下文信息。词嵌入的模型主要有 ```CBOW```、```Glove```、```Skip-gram```, 使用词嵌入可以使单词的每个维度都代表相应的含义。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''  \n",
    "使用已经训练好的预训练的 Glove 模型来进行相似度检验\n",
    "'''\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 指定 GloVe 预训练向量文件的路径\n",
    "glove_file = r'D:\\repo\\glove.6B.100d.txt'\n",
    "\n",
    "# 使用 Gensim 加载 GloVe 预训练向量\n",
    "model = KeyedVectors.load_word2vec_format(glove_file, binary=False, no_header=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity: [[0.906745]]\n"
     ]
    }
   ],
   "source": [
    "'''  \n",
    "使用词嵌入求文本相似度，把得到的单词对应的词嵌入向量相加求平均\n",
    "'''\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# 预处理文本\n",
    "def preprocessing(text):\n",
    "    return text.lower().split()\n",
    "\n",
    "def avg_vec(text, model):\n",
    "    words = preprocessing(text)\n",
    "    avg_vec_ = np.mean([model[word] for word in words if word in model], axis=0) # 每个单词对应一个sample, 求的是 sample 平均\n",
    "    return avg_vec_\n",
    "\n",
    "# 文本\n",
    "text1 = 'I like to play football.'\n",
    "text2 = 'I love playing football.'\n",
    "\n",
    "vec1 = avg_vec(text1, model).reshape(1, -1)\n",
    "vec2 = avg_vec(text2, model).reshape(1, -1)\n",
    "\n",
    "# 计算相似度\n",
    "cos_sim = cosine_similarity(vec1, vec2)\n",
    "print(f\"Similarity: {cos_sim}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到使用词嵌入，两句话的相似度很高。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果给定的文本文本相对较长，我们可以先用深度学习模型对其进行文本提取， 然后对于提取的文本摘要进行相似度计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
