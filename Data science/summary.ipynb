{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import f1_score, make_scorer, accuracy_score\n",
    "\n",
    "def cv_model(clf, X_train, y_train, X_test, clf_name, folds=5, seed=42):\n",
    "    '''   \n",
    "    params: \n",
    "        clf: 分类模型\n",
    "        X_train: 训练集特征，DataFrame对象\n",
    "        y_trian: 训练集标签\n",
    "        X_test: 测试集\n",
    "        clf_name: 分类模型的名称\n",
    "        folds: 折数\n",
    "        seed: 随机种子数值\n",
    "    '''\n",
    "    kfold = KFold(n_splits=folds, shuffle=True, random_state=True)\n",
    "    cv_scores = []\n",
    "    oof = np.zeros(X_train.shape[0])\n",
    "    test_predict = np.zeros(X_test.shape[0])\n",
    "    for i, (train_index, val_index) in enumerate(kfold.split(X_train, y_train)):\n",
    "        print(\"********************** || **********************\")\n",
    "        # 划分训练集和验证集\n",
    "        x_train_fold, y_train_fold = X_train.iloc[train_index], y_train[train_index]\n",
    "        x_val_fold, y_val_fold = X_train[val_index], y_train[val_index]\n",
    "\n",
    "        if clf_name == 'lgbm':\n",
    "            # 创建 Dataset 对象\n",
    "            train_data = clf.Dataset(data=x_train_fold,\n",
    "                                     label=y_train_fold,\n",
    "                                     weight=None) \n",
    "            val_data = clf.Dataset(data=x_val_fold,\n",
    "                                   label=y_val_fold,\n",
    "                                   weight=None)\n",
    "            \n",
    "            lgbm_params = {\n",
    "                'boosting_type': 'gbdt',  # 提升方法类型\n",
    "                'objective': 'binary',  # 指定学习任务和相应的损失函数\n",
    "                'min_child_weight': 6,  # 每个叶子的最小权重和\n",
    "                'num_leaves': 2 ** 6,  # 树上的最大叶子数\n",
    "                'lambda_l2': 10,  # L2 正则化系数, 用于控制模型的复杂度\n",
    "                'feature_fraction': 0.8,  # 每次迭代中使用的特征比列\n",
    "                'bagging_fraction': 0.8,  # 每次迭代时用于训练的数据比例\n",
    "                'bagging_freq': 4,  # bagging 的频率\n",
    "                'learning_rate': 0.25,  # 学习率\n",
    "                'seed': 42,  \n",
    "                'nthread': -1, \n",
    "                'verbose': -1,\n",
    "            }\n",
    "            model = clf.trian(params=lgbm_params,\n",
    "                              train_set=train_data,\n",
    "                              num_boost_round=1000,\n",
    "                              valid_sets=[train_data, val_data],\n",
    "                              early_stopping_rounds=100,\n",
    "                              verbose_eval=False)\n",
    "            val_pred = model.predict(x_val_fold, num_iteration=model.best_iteration)\n",
    "            test_pred  = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "        \n",
    "        if clf_name == 'xgb':\n",
    "\n",
    "            # 读取数据\n",
    "            train_data = clf.DMatrix(x_train_fold, label=y_train_fold)\n",
    "            val_data = clf.DMatrix(x_val_fold, label=y_val_fold)\n",
    "\n",
    "            xgb_params = {\n",
    "                'booster': 'gbtree',\n",
    "                'objective': 'binary:logistic',\n",
    "                'num_class': 1, # 类别数量\n",
    "                'max_depth': 6,\n",
    "                'lambda': 10,\n",
    "                'subsample': 0.7,  # 每棵树训练时使用的样本比例\n",
    "                'colsample_bytree': 0.7,  # 每棵树训练时使用的特征比例\n",
    "                'colsample_bylevel': 0.7,  # 每个数层级进行采样的比例\n",
    "                'eta': 0.2,  # 学习率\n",
    "                'tree_method': 'hist',  # 构建树的方法\n",
    "                'seed': 42\n",
    "            }\n",
    "            watchlist = [(train_data, 'train'), (val_data, 'eval')]\n",
    "            model = clf.train(xgb_params,\n",
    "                              train_data,\n",
    "                              num_boost_round=2000,\n",
    "                              evals=watchlist,\n",
    "                              verbose_eval=1000,\n",
    "                              early_stopping_roun=100)\n",
    "            val_pred = model.predict(val_data)\n",
    "            test_pred = model.predict(X_test)\n",
    "\n",
    "        if clf_name == 'catboost':\n",
    "            params = {\n",
    "                'learning_rate': 0.2, \n",
    "                'depth': 6,\n",
    "                'bootsrap_type': 'Bernoulli',\n",
    "                'random_seed': 11,\n",
    "                'od_type': 'Iter',\n",
    "                'od_wait': 100,\n",
    "                'allow_writing_files': False\n",
    "            }\n",
    "            model = clf(iteration=2000, **params)\n",
    "            model.fit(x_train_fold,\n",
    "                      y_train_fold,\n",
    "                      eval_set=(x_val_fold, y_val_fold),\n",
    "                      metric_period=1000,\n",
    "                      use_best_model=True,\n",
    "                      cat_features=[],\n",
    "                      verbose=1)\n",
    "            \n",
    "            val_pred = model.predict_proba(x_val_fold)\n",
    "            test_pred = model.predict_proba(X_test)\n",
    "\n",
    "        oof[val_index] = val_pred\n",
    "        test_predict += test_pred / kfold.get_n_splits()\n",
    "\n",
    "        F1_score = f1_score(y_val_fold, np.where(val_pred>0.5, 1, 0))\n",
    "        cv_scores.append(F1_score)\n",
    "        print(cv_scores)\n",
    "\n",
    "    return oof, test_predict\n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
